{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP NLKT的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例：分析语法树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例字符串：\"GE data science is all about real-time collaboration. Our teams are scattered around the world, and we want to be able to collaborate in real time. We want to have a common machine learning platform that everyone can use for modern analytics, and set standards that everyone can follow. Anaconda Enterprise allows us to do this in a very efficient way.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"GE data science is all about real-time collaboration. Our teams are scattered around the world, \n",
    "and we want to be able to collaborate in real time. \n",
    "We want to have a common machine learning platform that everyone can use for modern analytics, \n",
    "and set standards that everyone can follow. Anaconda Enterprise allows us to do this in a very efficient way.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分词\n",
    "words = nltk.word_tokenize(s)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签\n",
    "tags = nltk.pos_tag(words)\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签含义\n",
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成语法树\n",
    "chunk = nltk.chunk.ne_chunk(tags)\n",
    "chunk.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例：寻找近似词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#布朗语料库\n",
    "l = nltk.corpus.brown.words()\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全部变成小写\n",
    "l2 = [w.lower() for w in l]\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合成整段文本\n",
    "text = nltk.Text(l2)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the的近似词（不是近义词）\n",
    "text.similar('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例：通过姓名识别性别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.words('male.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names.words('female.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取名字，标注性别\n",
    "l = [(name,'男') for name in names.words('male.txt')] + [(name,'女') for name in names.words('female.txt')]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#标注特征————注：这里使用结尾字母为特征\n",
    "l2 = [({'feature':name[-1]},gender) for (name,gender) in l]\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机排序\n",
    "random.shuffle(l2)\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分成两半\n",
    "train_set = l2[:math.floor(len(l2)/2)]  #floor()下取整\n",
    "test_set = l2[math.ceil(len(l2)/2):]    #ceil()上取整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据（朴素贝叶斯分类器）\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "classifier.classify({\"feature\":'candy'[-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "res = sum([1 if classifier.classify(features)==gender else 0 for(features,gender) in test_set])/len(test_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试一试：使用倒数两个字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取名字，标注性别  使用结尾2字母为特征\n",
    "l = [({\"feature\":name[-2:]},'男') for name in names.words('male.txt')] + [({\"feature\":name[-2:]},'女') for name in names.words('female.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机排序\n",
    "random.shuffle(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分成两半\n",
    "train_set = l[:math.floor(len(l)/2)]  #floor()下取整\n",
    "test_set = l[math.ceil(len(l)/2):]    #ceil()上取整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据（朴素贝叶斯分类器）\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "res = sum([1 if classifier.classify(features)==gender else 0 for(features,gender) in test_set])/len(test_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 另一种方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk\n",
    "import random\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(s):\n",
    "    res = {}\n",
    "    for w in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        res[w] = 0\n",
    "    \n",
    "    for w in s:\n",
    "        w = w.lower()\n",
    "        \n",
    "        if w in res:\n",
    "            res[w]+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取名字，标注性别  使用结尾2字母为特征\n",
    "l = [(get_features(name),'男') for name in names.words('male.txt')] + [(get_features(name),'女') for name in names.words('female.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机排序\n",
    "random.shuffle(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分成两半\n",
    "train_set = l[:math.floor(len(l)/2)]  #floor()下取整\n",
    "test_set = l[math.ceil(len(l)/2):]    #ceil()上取整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据（朴素贝叶斯分类器）\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "res = sum([1 if classifier.classify(features)==gender else 0 for(features,gender) in test_set])/len(test_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用首字母与末字母"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "import nltk\n",
    "import random\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(s):\n",
    "    res = {}\n",
    "    for w in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "        res[w] = 0\n",
    "    \n",
    "    for w in s:\n",
    "        w = w.lower()\n",
    "        \n",
    "        if w in res:\n",
    "            res[w]+=1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#读取名字，标注性别  使用结尾2字母为特征\n",
    "l = [({\"last\":name[-1],\"first\":name[0]},'男') for name in names.words('male.txt')] + [({\"last\":name[-1],\"first\":name[0]},'女') for name in names.words('female.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机排序\n",
    "random.shuffle(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分成两半\n",
    "train_set = l[:math.floor(len(l)/2)]  #floor()下取整\n",
    "test_set = l[math.ceil(len(l)/2):]    #ceil()上取整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练数据（朴素贝叶斯分类器）\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "res = sum([1 if classifier.classify(features)==gender else 0 for(features,gender) in test_set])/len(test_set)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建中文语法树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import jieba\n",
    "import jieba.posseg as posseg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "示例字符串：\"美国司法部表示，华特迪士尼获准以713亿美元收购二十一世纪福克斯的娱乐资产，前提条件是迪士尼出售福克斯的22个地方体育电视网络。迪士尼同意出售福克斯的22个地区性体育频道，以解决司法部对该交易可能导致地方市场有线电视体育节目涨价的担心。迪士尼称，很高兴与美国司法部达成这项协议，称希望带来更吸引人的用户体验。此外，美国最大的有线电视运营商康卡斯特仍有意竞购21世纪福克斯的娱乐资产。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"\"\"美国司法部表示，华特迪士尼获准以713亿美元收购二十一世纪福克斯的娱乐资产，前提条件是迪士尼出售福克斯的22个地方体育电视网络。迪士尼同意出售福克斯的22个地区性体育频道，以解决司法部对该交易可能导致地方市场有线电视体育节目涨价的担心。迪士尼称，很高兴与美国司法部达成这项协议，称希望带来更吸引人的用户体验。此外，美国最大的有线电视运营商康卡斯特仍有意竞购21世纪福克斯的娱乐资产。\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir() 返回模块的属性列表。\n",
    "dir(list(posseg.cut(s))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [(item.word,item.flag) for item in list(posseg.cut(s))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = nltk.chunk.ne_chunk(tags)\n",
    "chunk.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实例：新闻分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-6-9ba3ec9194d7>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-9ba3ec9194d7>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    path = '\\text\\'\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "path = '\\text\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'C:\\\\Users\\\\MrLen\\\\AnacondaProjects/text/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-53dd4fa4863a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#1.读文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'C:\\\\Users\\\\MrLen\\\\AnacondaProjects/text/'"
     ]
    }
   ],
   "source": [
    "#1.读文件\n",
    "types = os.listdir(os.getcwd() + path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ee1dae09b80f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdatas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'types' is not defined"
     ]
    }
   ],
   "source": [
    "for name in types:\n",
    "    datas[name] = []\n",
    "    print(name)\n",
    "    \n",
    "    for filename in os.listdir(os.getcwd() + path + name):\n",
    "        fp = open(os.getcwd() + path + name + '/' + filename,'r',encoding = \"utf-8\")\n",
    "        content = fp.read()\n",
    "        fp.close()\n",
    "        \n",
    "        datas[name].append(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
